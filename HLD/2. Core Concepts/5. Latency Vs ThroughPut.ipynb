{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latency\n",
    "\n",
    "Definition: \n",
    "\n",
    "Latency measures delay—how long it takes for a single request to be processed from start to finish. In other words, it's the delay between the initiation of a request and the receipt of the response. Think of it as the time you wait at a fast-food drive-thru to get your order.\n",
    "\n",
    "Characteristics:\n",
    "Measured in units of time (milliseconds, seconds).\n",
    "Lower latency indicates a more responsive system.\n",
    "\n",
    "Impact: Latency is particularly important in scenarios where real-time or near-real-time interaction or data transfer is crucial, such as in online gaming, video conferencing, or high-frequency trading.\n",
    "\n",
    "Example: If you click a link on a website, the latency would be the time it takes from the moment you click the link to when the page starts loading.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Throughput\n",
    "\n",
    "Definition: \n",
    "\n",
    "Throughput refers to the amount of data transferred over a network or processed by a system in a given amount of time. It's a measure of how much work or data processing is completed over a specific period.\n",
    "\n",
    "Characteristics:\n",
    "\n",
    "Measured in units of data per time (e.g., Mbps - Megabits per second).\n",
    "\n",
    "Higher throughput indicates a higher data processing capacity.\n",
    "\n",
    "Impact: \n",
    "\n",
    "Throughput is a critical measure in systems where the volume of data processing is significant, such as in data backup systems, bulk data processing, or video streaming services.\n",
    "\n",
    "Example: \n",
    "\n",
    "In a video streaming service, throughput would be the rate at which video data is transferred from the server to your device.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Latency vs Throughput - Key Differences\n",
    "\n",
    "1. Focus: Latency is about the delay or time, focusing on speed. Throughput is about the volume of work or data, focusing on capacity.\n",
    "\n",
    "2. Influence on User Experience: High latency can lead to a sluggish user experience, while low throughput can result in slow data transfer rates, affecting the efficiency of data-intensive operations.\n",
    "\n",
    "3. Trade-offs: In some systems, improving throughput may increase latency, and vice versa. For instance, sending data in larger batches may improve throughput but could also result in higher latency.\n",
    "\n",
    "Improving latency and throughput often involves different strategies, as optimizing for one can sometimes impact the other. However, there are several techniques that can enhance both metrics:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Factors Influencing Latency\n",
    "\n",
    "1. **Network Distance**: More hops and longer physical distance increase delay.\n",
    "\n",
    "2. **Bandwidth Limitations**: Limited capacity slows down data transfer.\n",
    "\n",
    "3. Server Processing Time: How long the system takes to handle requests.\n",
    "\n",
    "4. Congestion: Too many users cause network or server bottlenecks.\n",
    "\n",
    "5. **Protocol Overhead**: Communication protocols like TCP add handshake delays.\n",
    "\n",
    "6. Hardware Performance: Slow CPUs, storage, or routers add latency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# How to Improve Latency\n",
    "\n",
    "1. Optimize Network Routes: \n",
    "\n",
    "Use Content Delivery Networks (CDNs) to serve content from locations geographically closer to the user. This reduces the distance data must travel, decreasing latency.\n",
    "\n",
    "2. Caching Frequently Accessed Data: \n",
    "\n",
    "Cache frequently accessed data in memory to eliminate \n",
    "the need to fetch data from the original source repeatedly.\n",
    "\n",
    "3. Upgrade Hardware:\n",
    "\n",
    "Faster processors, more memory, and quicker storage (like SSDs) can reduce processing time.\n",
    "\n",
    "4. Use Faster Communication Protocols: \n",
    "\n",
    "Protocols like HTTP/2 can reduce latency through features like multiplexing and header compression.\n",
    "\n",
    "5. Database Optimization: \n",
    "\n",
    "Use indexing, optimized queries, and in-memory databases to reduce data access and processing time.\n",
    "\n",
    "6. Load Balancing: \n",
    "\n",
    "Distribute incoming requests efficiently among servers to prevent any single server from becoming a bottleneck.\n",
    "\n",
    "7. Code Optimization: \n",
    "\n",
    "Optimize algorithms and remove unnecessary computations to speed up execution.\n",
    "\n",
    "8. Minimize External Calls: \n",
    "\n",
    "Reduce the number of API calls or external dependencies in your application.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# How to Improve Throughput\n",
    "\n",
    "1. Scale Horizontally:\n",
    "\n",
    "Add more servers to handle increased load. This is often more effective than vertical scaling (upgrading the capacity of a single server).\n",
    "\n",
    "2. Implement Caching: \n",
    "\n",
    "Cache frequently accessed data in memory to reduce the need for repeated data processing.\n",
    "\n",
    "3. Parallel Processing: \n",
    "\n",
    "Use parallel computing techniques where tasks are divided and processed simultaneously.\n",
    "\n",
    "4. Batch Processing: \n",
    "\n",
    "For non-real-time data, processing in batches can be more efficient than processing each item individually.\n",
    "\n",
    "5. Optimize Database Performance: \n",
    "\n",
    "Ensure efficient data storage and retrieval. This may include techniques like partitioning and sharding.\n",
    "\n",
    "6. Asynchronous Processing: \n",
    "\n",
    "Use asynchronous processes for tasks that don’t need to be completed immediately.\n",
    "\n",
    "7. Network Bandwidth: \n",
    "\n",
    "Increase the network bandwidth to accommodate higher data transfer rates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factors Influencing Throughput:\n",
    "\n",
    "1. Bandwidth Capacity: Determines how much data can be moved at once.\n",
    "\n",
    "2. Concurrency: Number of simultaneous users or threads.\n",
    "\n",
    "3. System Resources: CPU, memory, disk I/O, and network capacity.\n",
    "\n",
    "4. Queue Management: Delays in message or task queues.\n",
    "\n",
    "4. Application Design: Inefficient algorithms reduce processing capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.designgurus.io/course-play/grokking-the-system-design-interview/doc/latency-vs-throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
